---
title: "Don‚Äôt Outsource Your Perspective to a LLM"
date: 2024-02-02 11:44:53 -07:00
comments: true
tags: ["AI/ML", "writing"]
description: "I‚Äôm seeing a lot of article pitches lately that were clearly written by a Large Language Model rather than a human being. There was clearly some thought put into the prompt, but no follow though to really take ownership of the resulting output. Please don‚Äôt be ‚Äúthat guy.‚Äù"
twitter_text: "I‚Äôm seeing a lot of article pitches that were clearly written by a #LLM. The submitters clearly put some thought into the prompts, but didn‚Äôt bother putting any effort into owning the output."
hero:
  src: /i/posts/2024-02-02/hero.jpg
  credit: "Aaron Gustafson √ó Designer"
  alt: "A person playing trumpet and a robot playing drums are on a stage in a jazz band. They are looking at each other. In the style of a 60s jazz album cover."
  url: https://www.bing.com/images/create/a-person-playing-trumpet-and-a-robot-playing-drums/1-65bd5c702f59457583b11e08515eb603?id=mPSMVHOoB6ulGJYLeL5I6Q%3d%3d&view=detailv2&idpp=genimg&FORM=GCRIDP&mode=overlay
  offset: "60"
---

At [<cite>A List Apart</cite>](https://alistapart.com/), I‚Äôm seeing a lot of article pitches that were clearly written by a Large Language Model (LLM) rather than a human being. In many cases, the people making the submission clearly put a lot of thought into the prompts they used to get the output they desired, but had zero follow though when it came to taking ownership of the output they were handed. To be clear, the issue I have here is not that they used an LLM as part of their process, but rather how they failed to wield such powerful tool effectively.

<!-- more -->

## Improv

A while back, I read [a great piece from Johnathan May](https://theconversation.com/chatgpt-is-great-youre-just-using-it-wrong-198848) that discussed where LLMS fail us (factual knowledge) and where they excel (conversation). He highlighted how awful they are when it comes to retrieving facts (LLMs are _not_ the reference librarian you think they are), but how useful they can when factuality is not as important. Armed with this knowledge, he did some experimentation and discovered how well LLMs perform as an improv partner‚Ä¶ someone to bounce ideas off of.

It was with that idea in mind that I decided to test out this approach when working on [my axe-con keynote ](https://presentations.aaron-gustafson.com/SE8HHb/accessibility-beyond-code-compliance) last year. I already had an outline for the talk and knew what I wanted to say, but took some time to bounce my ideas off of ChatGPT and see how it responded to them. In most cases it responded with paragraphs of prose clearly demonstrating its lack of reasoning on any subject‚Äînot surprising though, LLMs are word prediction engines. In other instances, however, it surprised me with how the words it predicted managed to "frame"[^1] particular concepts in novel ways, prompting me to think differently about how I might approach it in my talk.

[^1]: To be clear, I am not trying to anthropomorphize the LLM here.

I feel confident claiming that [the talk](https://www.aaron-gustafson.com/notebook/accessibility-beyond-code-compliance/) was entirely a product of my own efforts. At the same time, I‚Äôm also appreciative of ChatGPTs role as an improv partner in the process of creating it.

## Hope

I guess I‚Äôm hopeful more people will embrace using LLMs in this way. We need to recognize what tools like these are good at and what they aren‚Äôt. Hammers are awesome at driving in nails, but they‚Äôre only reasonably good at removing them‚Äîfrom wood, yes; from drywall no. Hammers are also the entirely wrong tool if you‚Äôre looking to drive or remove a screw.

LLMs are excellent at reworking stuff you‚Äôve written‚Äîsummarizing content, adjusting it to a particular reading level, helping you craft a suitable conclusion for an article or talk based on your existing content. [They are not fact machines](https://www.scientificamerican.com/article/to-educate-students-about-ai-make-them-use-it/). Furthermore, they can‚Äôt replicate or replace your unique perspective on a subject and that‚Äôs the very humanness that makes your writings, talks, and other forms of communication worthy of our time.

## Parting words

If you find LLMs useful in your process, more power to you. If you don‚Äôt, that‚Äôs cool too. Just be aware of their limitations while embracing their power to help. And don‚Äôt ever try to pass off their writing as your own. Not only can we tell, but it robs us of the chance to hear what _you_ think. And that‚Äôs what we really want to read.

P.S. - In case you‚Äôre wondering: No, I didn‚Äôt use an LLM to help me write this post üòâ
